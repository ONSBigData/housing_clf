{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using textual descriptions, find restricted access properties within Zoopla data\n",
    "#### What are restricted access properties?Â¶\n",
    "- Restricted access properties are properties such as secure access flats or gated communities\n",
    "- These are either inconsistently recorded in other data sources or not at all\n",
    "- Identifying them will improve the Address Register\n",
    "- It will also help to make field work more efficient if enumerators know they will have difficulty with access\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Timestamp\n",
    "import statsmodels\n",
    "from operator import itemgetter\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import bigrams\n",
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.util import mark_negation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipelines for each classifier (to be used further down)\n",
    "- Classifiers include; Logistic regression, Support Vector Machines, Neural Networks, Stochastic Gradient Descent and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) LOGISTIC REGRESSION\n",
    "LR_trigram_clf = Pipeline([\n",
    "\n",
    "\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"word\",\n",
    "                                   ngram_range=(1, 3),\n",
    "                                   tokenizer=word_tokenize,         \n",
    "                                   max_features=10000)),\n",
    "    ('transformer', TfidfTransformer()) ,    \n",
    "    ('classifier', LogisticRegression(C=2.0, penalty='l2'))     \n",
    "    \n",
    "   \n",
    "])\n",
    "\n",
    "# 2) SUPPORT VECTOR MACHINES\n",
    "svm_trigram_clf = Pipeline([\n",
    "\n",
    "\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"word\",\n",
    "                                   ngram_range=(1, 3),\n",
    "                                   tokenizer=word_tokenize,         \n",
    "                                   max_features=10000)),\n",
    "    ('classifier', LinearSVC())     \n",
    "    \n",
    "   \n",
    "])\n",
    "\n",
    "\n",
    "# 3) NAIVE BAYES\n",
    "NB_trigram_clf = Pipeline([\n",
    "\n",
    "\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"word\",\n",
    "                                   ngram_range=(1, 3),\n",
    "                                   tokenizer=word_tokenize,         \n",
    "                                   max_features=10000)),\n",
    "\n",
    "    ('classifier', MultinomialNB())    \n",
    "    \n",
    "   \n",
    "])\n",
    "\n",
    "# 4) STOCHASTIC GRADIENT DESCENT REGRESSION\n",
    "SGD_trigram_clf = Pipeline([\n",
    "\n",
    "\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"word\",\n",
    "                                   ngram_range=(1, 3),\n",
    "                                   tokenizer=word_tokenize,         \n",
    "                                   max_features=10000)),\n",
    "    ('classifier', SGDClassifier()) \n",
    "    \n",
    "   \n",
    "])\n",
    "\n",
    "# 5) RANDOM FORESTS\n",
    "random_clf = Pipeline([\n",
    "\n",
    "\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"word\",\n",
    "                                   ngram_range=(1, 2),\n",
    "                                   tokenizer=word_tokenize,         \n",
    "                                   max_features=10000)),\n",
    "    ('transformer', TfidfTransformer()) ,    \n",
    "    ('classifier', RandomForestClassifier())     \n",
    "    \n",
    "   \n",
    "])\n",
    "\n",
    "\n",
    "#6) NEURAL NETWORKS\n",
    "NN_trigram_clf = Pipeline([\n",
    "\n",
    "\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"word\",\n",
    "                                   ngram_range=(1, 3),\n",
    "                                   tokenizer=word_tokenize,       \n",
    "                                   max_features=10000)),\n",
    "\n",
    "    ('transformer', TfidfTransformer()),\n",
    "    ('classifier', MLPClassifier(learning_rate_init=0.01,\n",
    "                    hidden_layer_sizes=10, max_iter=100, activation='tanh', verbose=100,\n",
    "                    early_stopping=True, validation_fraction=0.05, alpha=1e-10)) \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to show what the most informative features of restricted access properties are for each classifier\n",
    "- This will display the top 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_most_informative_features(model, text=None, n=20):\n",
    "    \"\"\"\n",
    "    Accepts a Pipeline with a classifer and a TfidfVectorizer and computes\n",
    "    the n most informative features of the model. If text is given, then will\n",
    "    compute the most informative features for classifying that text.\n",
    "    Note that this function will only work on linear models with coefs_\n",
    "    \"\"\"\n",
    "    # Extract the vectorizer and the classifier from the pipeline\n",
    "    vectorizer = model.named_steps['vectorizer']\n",
    "    classifier = model.named_steps['classifier']\n",
    "\n",
    "    # Check to make sure that we can perform this computation\n",
    "    if not hasattr(classifier, 'coef_'):\n",
    "        raise TypeError(\n",
    "            \"Cannot compute most informative features on {} model.\".format(\n",
    "                classifier.__class__.__name__\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if text is not None:\n",
    "        # Compute the coefficients for the text\n",
    "        tvec = model.transform([text]).toarray()\n",
    "    else:\n",
    "        # Otherwise simply use the coefficients\n",
    "        tvec = classifier.coef_\n",
    "\n",
    "    # Zip the feature names with the coefs and sort\n",
    "    coefs = sorted(\n",
    "        zip(tvec[0], vectorizer.get_feature_names()),\n",
    "        key=itemgetter(0), reverse=True\n",
    "    )\n",
    "\n",
    "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
    "\n",
    "    # Create the output string to return\n",
    "    output = []\n",
    "\n",
    "    # If text, add the predicted value to the output.\n",
    "    if text is not None:\n",
    "        output.append(\"\\\"{}\\\"\".format(text))\n",
    "        output.append(\"Classified as: {}\".format(model.predict([text])))\n",
    "        output.append(\"\")\n",
    "\n",
    "    # Create two columns with most negative and most positive features.\n",
    "    for (cp, fnp), (cn, fnn) in topn:\n",
    "        output.append(\n",
    "            \"{:0.4f}{: >15}    {:0.4f}{: >15}\".format(cp, fnp, cn, fnn)\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data and define labels\n",
    "- Import csvs and clerical review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf= pd.read_csv('clean_wf.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of listings with missing descriptions (cannot use these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf= wf[wf['description_parsed'] != 'missing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a subset of records that are not restricted access in order to even up the training set. To do this, we negated search terms you'd expect to generate restricted access and created a sample (which was then checked to see if there was anything unexpected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wflabelfalse = wf[~wf.description_parsed.str.contains('secure access|gated community|concierge|development is gated|gated access|gated development|gated cul-de-sac|private gated mews')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wfsamplefalse = wflabelfalse.sample(n=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wfsamplefalse['label'] = 0 # Give these a label of 0 for false, we'll import true values further down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 =  wfsamplefalse[['description_parsed','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.to_csv('df1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot checks on the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 50)\n",
    "df1.description_parsed[111:112]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in records from the wf data that have been clerically reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('clerical_restricted.csv',encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge dataframes to give a balanced set ready for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "df = pd.concat(frames)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text'] = df['description_parsed'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def removeStopWords(input):\n",
    "    exclude = set(string.punctuation)\n",
    "    output = ' '.join([word for word in input.split() if word not in stopwords.words(\"english\")])\n",
    "    output = ''.join(ch for ch in output if ch not in exclude)\n",
    "        \n",
    "    return pd.Series(dict(output=output))\n",
    "\n",
    "df['ml_text'] = df['text'].apply(lambda x: removeStopWords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_non_ascii (text):\n",
    "    return ''.join(i for i in text if ord(i)<128)\n",
    "                   \n",
    "def replacenon_ascii_w_space (text):\n",
    "    return ''.join([i if ord(i) < 128 else ' ' for i in text])\n",
    "\n",
    "df['ml_text'] = df['ml_text'].apply(lambda x: remove_non_ascii(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming the textual descriptions\n",
    "- We do this because we want to reduce the words to their minimum most informative meaning. \n",
    "- Therefore when doing the machine learning, the classifiers can be informed about when the text refers to the same word e.g. house, housing and houses all become hous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and create the stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this for each description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['stem_text']  = df['ml_text'].apply(lambda x: ' '.join([porter_stemmer.stem(y) for y in x.split()]))\n",
    "df.drop(['Unnamed: 0', 'description_parsed', 'text', 'token_text', 'ml_text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation for Machine Learning\n",
    "- Here we need to split the data into X and Y values\n",
    "- The X being the textual descriptions, y being the 'truth' labels\n",
    "- In training, the classifiers will use both to learn and make associations between what a restricted access property is and what it isn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df['stem_text'].values.astype('U')\n",
    "y=df['label'].values\n",
    "z= df['id'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split between training set and test set\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(LR_trigram_clf.fit(train_X, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(LR_trigram_clf.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5-fold crossvalidation\n",
    "scores = cross_val_score(LR_trigram_clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"-----------------LR trigram pipeline------\")\n",
    "print (scores)\n",
    "print (np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(show_most_informative_features(LR_trigram_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM trigrams classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(svm_trigram_clf.fit(train_X, train_y))\n",
    "print(svm_trigram_clf.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5-fold crossvalidation\n",
    "\n",
    "scores = cross_val_score(svm_trigram_clf, X, y, cv=5)\n",
    "\n",
    "print(\"-----------------SVM trigram pipeline------\")\n",
    "print (scores)\n",
    "print (np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(show_most_informative_features(svm_trigram_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.learning_curve import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure()\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X_new, y, cv=5, n_jobs=1, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(\"on\") \n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, grid_search\n",
    "\n",
    "count_vect = TfidfVectorizer()\n",
    "X_new = count_vect.fit_transform(test_X)\n",
    "\n",
    "print(X_new.shape)\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(NB_trigram_clf.fit(train_X, train_y))\n",
    "print(NB_trigram_clf.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5-fold cross validation\n",
    "\n",
    "scores = cross_val_score(NB_trigram_clf, X, y, cv=5)\n",
    "\n",
    "print(\"-----------------NB trigram pipeline------\")\n",
    "print (scores)\n",
    "print (np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(show_most_informative_features(NB_trigram_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(NN_trigram_clf.fit(train_X, train_y))\n",
    "print(NN_trigram_clf.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5-fold cross validation\n",
    "\n",
    "scores = cross_val_score(NN_trigram_clf, X, y, cv=5)\n",
    "\n",
    "print(\"-----------------NN trigram pipeline------\")\n",
    "print (scores)\n",
    "print (np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(SGD_trigram_clf.fit(train_X, train_y))\n",
    "print(SGD_trigram_clf.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5-fold crossvalidation\n",
    "\n",
    "scores = cross_val_score(SGD_trigram_clf, X, y, cv=5)\n",
    "\n",
    "print(\"-----------------SGD trigram pipeline------\")\n",
    "print (scores)\n",
    "print (np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(show_most_informative_features(SGD_trigram_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SK Learn classification report\n",
    "from sklearn import svm, grid_search\n",
    "\n",
    "count_vect = TfidfVectorizer()\n",
    "X_transformed = count_vect.fit_transform(train_X)\n",
    "\n",
    "count_vect.vocabulary_.get(u'restricted')\n",
    "\n",
    "clf = LogisticRegression().fit(X_transformed, train_y)\n",
    "X_new_counts = count_vect.transform(test_X)\n",
    "\n",
    "y_pred = clf.predict(X_new_counts)\n",
    "y_pred_prob = LR_trigram_clf.predict_proba(test_X)[:,1]\n",
    "print(classification_report(test_y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clf.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_transformed.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_prob = LR_trigram_clf.predict_proba(test_X)[:,1]\n",
    "LR_output = pd.DataFrame({'test_X':test_X,'Y_pred':y_pred,'test_y':test_y,'Y_pred_prob':y_pred_prob})\n",
    "sout = LR_output.sort_values(['Y_pred_prob', 'Y_pred'], ascending=[False, False])\n",
    "sout.to_html(\"LRCLFtest.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plots\n",
    "- ROC curve\n",
    "- Calibration plot\n",
    "- Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve- This is useful  to understand the true positive and false positive rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc,brier_score_loss\n",
    "from ggplot import *\n",
    "\n",
    "preds = LR_trigram_clf.predict_proba(test_X)[:,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(test_y, preds)\n",
    "\n",
    "df_pred = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
    "\n",
    "    \n",
    "auc = metrics.auc(fpr,tpr)\n",
    "prob_pos = LR_trigram_clf.predict_proba(test_X)[:, 1]\n",
    "br=brier_score_loss(test_y, prob_pos)\n",
    "print(\"Area under Curve: \",auc,\"   Brier Score (the lower the better) \",br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ggplot(df_pred, aes(x='fpr', y='tpr')) +\\\n",
    "    geom_line() + \\\n",
    "    geom_abline(linetype='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibration curve- Useful to show how reliable the classifier is in comparison to what a perfectly calibrated model would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "for clf, name in [(LR_trigram_clf, 'trigram SVM ')]:\n",
    "    clf.fit(train_X, train_y)\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        prob_pos = clf.predict_proba(test_X)[:, 1]\n",
    "    else:  # use decision function\n",
    "        prob_pos = clf.decision_function(test_X)\n",
    "        prob_pos = \\\n",
    "            (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "    fraction_of_positives, mean_predicted_value = \\\n",
    "        calibration_curve(test_y, prob_pos, n_bins=10)\n",
    "\n",
    "    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "             label=\"%s\" % (name, ))\n",
    "\n",
    "    ax2.hist(prob_pos, range=(0, 1), bins=20, label=name,\n",
    "             histtype=\"step\", lw=2)\n",
    "\n",
    "ax1.set_ylabel(\"Fraction of positives\")\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "ax2.set_xlabel(\"Mean predicted value\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Confusion matrix to show True Positives/ False Positives/ False Negatives/ True Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_y, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print(cm)\n",
    "class_names = ['Positive (Restricted Access)', 'Negative (not Restriced Access)']\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    \n",
    "    classes = class_names\n",
    "    tick_marks = np.arange(len(classes)) \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "   \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\", fontsize= 20,\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_y, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Show confusion matrix in a separate window\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_trigram_clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Performing grid search\n",
    "- This will try different parameters for the model given specified metrics and return which parameters work the best.\n",
    "- We can use this to tune the model in order to attain optimum performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from scipy.stats import randint as sp_randint\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.001, 0.01, 0.1, 1.0], 'kernel': ['linear','rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(LR_trigram_clf, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_GS = GridSearchCV(cv=5, estimator=LogisticRegression(C=1.0, intercept_scaling=1, dual=False, fit_intercept=True, penalty='l2', tol=0.0001),\n",
    "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_GS.fit(X_transformed, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check best aspects to help with/ facilitate tuning of earlier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_GS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_trigram_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(clf_GS.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_trigram_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Need to open this in new book, do predictions based on this and see if it is the same\n",
    "- Therefore we pickle the data and the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('trigram_LR.pickle', 'wb') as f:\n",
    "    pickle.dump(LR_trigram_clf, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('X.pickle', 'wb') as f:\n",
    "    pickle.dump(X, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('y.pickle', 'wb') as f:\n",
    "    pickle.dump(y, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
